{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Retrieval-Augmented Generation (RAG) approach for Question-Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook we will explore the **Retrieval Augmentated Generation (RAG)** approach to use with a Large Language Model (LLM) to answer questions based on a reference file. In our case, we will use a pdf file that model has not seen before, and test its ability to generate responces based on the content of the pdf file. \n",
    "\n",
    "This notebook is based on a template hosted on [GitHub](https://www.youtube.com/watch?v=0xyXYHMrAP0&t=1173s) and tutorial hosted on [YouTube](https://www.youtube.com/watch?v=0xyXYHMrAP0&t=1173s) by James Calam. We have customized portions of the code to fit our particular needs.\n",
    "\n",
    "In this project we will use Flan T5 XL for an LLM, MimiLM as an embedding model and Pinecone for vector database. All code is executed on SageMaker, using S3 as the storage for the reference file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    sagemaker==2.173.0 \\\n",
    "    pinecone-client==2.2.1 \\\n",
    "    ipywidgets==7.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Flan-T5-XL from HuggingFace \n",
    "\n",
    "The first step in building this project is to deploy the LLM. FLAN (Fine-tuned LAnguage Net) T5 XL is a model produced by Google Research. It's predecesor is T5 model developed in 2019 [Jacob, 2023](https://exemplary.ai/blog/flan-t5). FLAN-T5 is a text-to-text transformer model, that can be used on language tasks, including translation, classification, and question-answering. As this was the model used in the tutorial, we chose to use it in this project as well for its size and performance. The model is smaller and known for its speed and efficiency in comparisom to other larger models, meanwhile having a comparative performance [Jacob, 2023](https://exemplary.ai/blog/flan-t5). \n",
    "\n",
    "We will upload the model from HuggingFace Models library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import (\n",
    "    HuggingFaceModel,\n",
    "    get_huggingface_llm_image_uri\n",
    ")\n",
    "\n",
    "role = sagemaker.get_execution_role() # IAM role to use by SageMaker\n",
    "\n",
    "hub_config = {\n",
    "    'HF_MODEL_ID':'google/flan-t5-xl', # model_id from hf.co/models\n",
    "    'HF_TASK':'text-generation' # Specifies the task\n",
    "}\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"0.8.2\"\n",
    ")\n",
    "\n",
    "# create the model\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub_config,\n",
    "    role=role, \n",
    "    image_uri=llm_image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will deploy the model. Depending on the instance, it might take a different amount of time. Our deployment took no longer than 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "llm = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.4xlarge\",\n",
    "    endpoint_name=\"flan-t5-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking LLM a question without providing it with the source knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have configured and deployed our model. Now we will experiment with asking the LLM a question without providing it with any context and see how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'University of Cambridge'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is Diana's education?\"\n",
    "\n",
    "out = llm.predict({\"inputs\": question})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a nice answer but unfortunatelly, that is not true. This example illustrates why RAG is important. With the RAG approach, we provide extra information, combined with a prompt and send both to the model together with the question. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = \"\"\"Diana attended Carleton Univesrsity in 2017 and she graduated in 2021.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the FLAN T5 XL is \"instruction finetuned\", meaning we can provide the model with a template to perform a specific language task, we can direct it to use the context we provided to answer our question ([Jacob, 2023](https://exemplary.ai/blog/flan-t5), [Bosma & Wei, 2021](https://blog.research.google/2021/10/introducing-flan-more-generalizable.html)).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]: What is Diana's education?\n",
      "[Output]: Carleton Univesrsity\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Answer the following QUESTION based on the CONTEXT\n",
    "given. If you do not know the answer and the CONTEXT doesn't\n",
    "contain the answer truthfully say \"I don't know\".\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "text_input = prompt_template.replace(\"{context}\", context).replace(\"{question}\", question)\n",
    "\n",
    "out = llm.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Input]: {question}\\n[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that is better! We can also ask it the question we did not provide the context to and see how it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]: What was my major?\n",
      "[Output]: I don't know\n"
     ]
    }
   ],
   "source": [
    "unanswerable_question = \"What was my major?\"\n",
    "\n",
    "text_input = prompt_template.replace(\"{context}\", context).replace(\"{question}\", unanswerable_question)\n",
    "\n",
    "out = llm.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Input]: {unanswerable_question}\\n[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it follows the instruction. This approach works, however as James Calam explains in the tutorial, it is not a good idea to feed the model with whatever context you have and start asking it questions. First, it defeats the purpose of having an LLM in the first place. Second, in the real world, we would be working with hundrends if not thousands of documents. Feeding the context of these documents to an LLM as an input has actually a negative impact on its performance, [link to tutorial](https://www.youtube.com/watch?v=0xyXYHMrAP0&t=1173s). The article that James mentiones which explains this issue is called [\"Lost in the Middle: How Language Models Use Long Contexts\"](https://arxiv.org/abs/2307.03172). \n",
    "\n",
    "What we will do instead is to feed a large body of information and retrieve relevant context to our question. This is the basis of **RAG**. In the next section we will deploy the embedding model. An embedding model creates embeddings for our context document (a pdf file) which we then store in a vector storage space. For our purpose, we would create an embedding for our question using the same embedding model. Then, we would retrieve relevant contents in the embedding space based on our question and feed these to the LLM to generate the correct answer.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy MiniLM-L6-V2 - an embedding model from HuggingFace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MiniLM-L6-V2 from the HuggingFace library as the embedding model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hub_config = {\n",
    "    'HF_MODEL_ID': 'sentence-transformers/all-MiniLM-L6-v2', # model_id from hf.co/models\n",
    "    'HF_TASK': 'feature-extraction'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub_config,\n",
    "    role=role,\n",
    "    transformers_version=\"4.6\", # transformers version used\n",
    "    pytorch_version=\"1.7\", # pytorch version used\n",
    "    py_version=\"py36\", # python version of the DLC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "encoder = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.large\",\n",
    "    endpoint_name=\"minilm-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = encoder.predict({\"inputs\": [\"some text here\", \"some more text goes here too\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.mean(np.array(out), axis=1)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def embed_docs(docs: List[str]) -> List[List[float]]:\n",
    "    out = encoder.predict({'inputs': docs})\n",
    "    embeddings = np.mean(np.array(out), axis=1)\n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have configured the embedding model, we will process to load the pdf file and extract its contents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a PDF file from S3 storage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we would like to use something that the model could not have been exposed to during training. Therefore we will be using a resume I created back in 2019 and updated recently. To retrieve it from S3, we will specify the bucket and the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from boto3.session import Session\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id= 'your_access_key', aws_secret_access_key= 'your_secret_key')\n",
    "with open('Resume_2019.pdf', 'wb') as f:\n",
    "    s3.download_fileobj('sagemaker-us-east-2-249342478614', 'Resume_2019.pdf', f)\n",
    "    f.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examening the PDF's contents and transforming it to feed into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read and transform the contents of the file, we will use two libraries: PyPDF and typing_extensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in pdf file: 2\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfReader('Resume_2019.pdf')\n",
    "print(\"Number of pages in pdf file:\", len(pdf.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diana\\nRogachova\\n(2019\\nresume)\\nOBJECTIVE\\nI\\nam\\na\\nhighly\\ndependable\\nand\\nwell-or ganized\\nindividual\\nseeking\\npart-time\\nemployment\\nin\\nthe\\ncustomer\\nservice\\nindustry .\\nI\\nam\\neager\\nto\\nprovide\\npositive\\nand\\nprofessional\\nservice\\nto\\nensure\\nclient\\nsatisfaction\\nand\\nrecurring\\nbusiness\\nopportunities.\\nWORK\\nEXPERIENCE\\nCashier\\nThe\\nRiv’s\\nSnack\\nBar,\\nSparks\\nSt,\\nOttawa,\\nON\\nJune\\n2019\\n–\\nCurr ent\\n●\\nDemonstrated\\nability\\nto\\nprovide\\noutstanding\\ncustomer\\nservice\\nby\\naccurately\\ntaking\\norders\\nand\\naddressing\\ncustomer\\ninquiries\\nwith\\na\\nfriendly\\nand\\nprofessional\\ndemeanor .\\n●\\nProven\\ntrack\\nrecord\\nof\\ncollaborating\\neffectively\\nwith\\nbartenders,\\ncooks,\\nmanagement\\nand\\nother\\nstaff\\nstreamlining\\nthe\\noperations.\\n●\\nProcessed\\ntransactions\\nwith\\naccuracy\\nand\\nefficiency ,\\nincluding\\ncash,\\ncredit\\ncards,\\nand\\ndigital\\npayments,\\nensuring\\na\\nseamless\\nand\\nefficient\\ncheckout\\nprocess\\nfor\\nguests.\\nSales\\nAssociate\\n(Sunday\\nonly\\nposition)\\nThe\\nUnrefined\\nOlive,\\nBank\\nSt,\\nOttawa,\\nON\\nSeptember\\n2018\\n–\\nCurr ent\\n●\\nStrengthened\\ninterpersonal\\nand\\npresentation\\nskills\\nby\\nproviding\\nan\\ninformative\\nservice\\nto\\neach\\nindividual\\ncustomer .\\n●\\nDemonstrated\\nexcellence\\nin\\ncustomer\\ncare\\nby\\nactively\\nlistening\\nto\\ncustomer ’s\\nneeds\\nand\\nused\\nmy\\nproduct\\nknowledge\\nto\\nfind\\nbest\\nmatches.\\n●\\nContributed\\nto\\nan\\nincrease\\nin\\nsales\\nduring\\nChristmas\\nin\\ncomparison\\nto\\nprevious\\nyears\\nby\\ngiving\\nadditional\\nproducts\\nrecommendations\\nand\\npromoting\\nseasonal\\ndeals.\\n●\\nFurther\\ndeveloped\\norganizational\\nand\\ntime-management\\nskills\\nby\\nperforming\\nmost\\nof\\nthe\\nstore’ s\\noperations\\nwithout\\nsupervision,\\nsuch\\nas\\nopening/closing,\\noperating\\na\\ncash\\nregister ,\\nanswering\\nphone\\ncalls,\\netc.\\nCashier\\nand\\nFood\\nServer\\nKettleman’ s\\nBagel\\nCo,\\nBank\\nSt,\\nOttawa,\\nON\\nApril\\n2017\\n–\\nAugust\\n2018\\n●\\nDemonstrated\\nan\\nexcellent\\nability\\nto\\nmultitask\\nand\\nstrengthened\\npriority\\nmanagement\\nskills\\nwhile\\nworking\\nin\\na\\nhigh\\nvolume,\\nfast\\npaced\\ncafé.\\n●\\nOften\\nsupervised\\n4-6\\nemployees\\nduring\\nbusy\\novernight\\nshifts\\nwith\\nthe\\ngoal\\nof\\ncompletion\\nof\\nmain\\ntasks\\n(wholesale\\norders,\\nbaking\\nfor\\nmorning\\nshifts,\\ncleaning\\nup,\\netc).●\\nStrengthened\\nconflict\\nresolution\\nskills\\nwhen\\ndealing\\nwith\\nvarious\\ncustomers’\\ncomplaints\\nby\\nattentively\\nlistening\\nand\\nfinding\\nthe\\nmost\\nappropriate\\nsolutions.\\n●\\nCoached\\nnew\\nemployees\\nin\\nthe\\ncomputer\\nsystem\\nand\\nimproved\\ntheir\\nperformance\\nwhich\\nincreased\\nthe\\nefficiency\\nof\\ntheir\\ntraining.\\nEDUCA TION\\nBachelor\\nof\\nArts\\nHonours\\nin\\nCriminology\\nand\\nCriminal\\nJustice\\nSystem:\\n2017-2021\\nPsychology\\nConcentration\\nCarleton\\nUniversity ,\\nOttawa,\\nON\\n●\\nCurrent\\nCGPA:\\n11.3/12.0\\nSKILLS\\n●\\nThree\\nyears\\nof\\ncustomer\\nservice\\nexperience\\nwith\\nproven\\ninterpersonal,\\ntime\\nmanagement\\nand\\norganizational\\nskills.\\n●\\nClear\\nand\\nstrong\\ncommunication\\nskills.\\nFluent\\nin\\nEnglish,\\nRussian\\nand\\nUkrainian.\\n●\\nComputer\\nskills:\\nAdvanced\\nin\\nMicrosoft\\nWord,\\nOutlook,\\nPowerPoint,\\nintermediate\\nin\\nExcel.\\nComfortable\\nwith\\nlearning\\nnew\\napplications\\nand\\nPOS\\nsystems.\\n●\\nHighly\\nresponsible\\nand\\nable\\nto\\nwork\\nwith\\nminimal\\nsupervision.\\n●\\nProven\\nability\\nto\\nwork\\nunder\\npressure\\nwith\\na\\ngreat\\ndegree\\nof\\nfocus\\nand\\nattention\\nto\\ndetails.\\n●\\nNatural\\nability\\nto\\nnegotiate\\nand\\nbuild\\nrelationships\\nwith\\nnew\\npeople.\\n●\\nFriendly\\nand\\nenthusiastic\\nin\\na\\nteam.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import Concatenate \n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdf.pages):\n",
    "    content = page.extract_text()\n",
    "    if content: \n",
    "        raw_text += content \n",
    "\n",
    "raw_text\n",
    "\n",
    "# code source: https://colab.research.google.com/drive/1Fk9um3Af_aV0WvavD01gVljPHAxzQNLp?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text is quite messy and unlikely that the model will be able to create appropriate embeddings. As such, we need to clean up this text.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry ',\n",
       " ' I am eager to provide positive and professional service to ensure client satisfaction and recurring business opportunities',\n",
       " ' WORK EXPERIENCE Cashier The Riv’s Snack Bar, Sparks St, Ottawa, ON June 2019 – Curr ent   Demonstrated ability to provide outstanding customer service by accurately taking orders and addressing customer inquiries with a friendly and professional demeanor ',\n",
       " '   Proven track record of collaborating effectively with bartenders, cooks, management and other staff streamlining the operations',\n",
       " '   Processed transactions with accuracy and efficiency , including cash, credit cards, and digital payments, ensuring a seamless and efficient checkout process for guests',\n",
       " ' Sales Associate (Sunday only position) The Unrefined Olive, Bank St, Ottawa, ON September 2018 – Curr ent   Strengthened interpersonal and presentation skills by providing an informative service to each individual customer ',\n",
       " '   Demonstrated excellence in customer care by actively listening to customer ’s needs and used my product knowledge to find best matches',\n",
       " '   Contributed to an increase in sales during Christmas in comparison to previous years by giving additional products recommendations and promoting seasonal deals',\n",
       " '   Further developed organizational and time-management skills by performing most of the store’ s operations without supervision, such as opening/closing, operating a cash register , answering phone calls, etc',\n",
       " ' Cashier and Food Server Kettleman’ s Bagel Co, Bank St, Ottawa, ON April 2017 – August 2018   Demonstrated an excellent ability to multitask and strengthened priority management skills while working in a high volume, fast paced café',\n",
       " '   Often supervised 4-6 employees during busy overnight shifts with the goal of completion of main tasks (wholesale orders, baking for morning shifts, cleaning up, etc)',\n",
       " '  Strengthened conflict resolution skills when dealing with various customers’ complaints by attentively listening and finding the most appropriate solutions',\n",
       " '   Coached new employees in the computer system and improved their performance which increased the efficiency of their training',\n",
       " ' EDUCA TION Bachelor of Arts Honours in Criminology and Criminal Justice System: 2017-2021 Psychology Concentration Carleton University , Ottawa, ON   Current CGPA: 11',\n",
       " '3/12',\n",
       " '0 SKILLS   Three years of customer service experience with proven interpersonal, time management and organizational skills',\n",
       " '   Clear and strong communication skills',\n",
       " ' Fluent in English, Russian and Ukrainian',\n",
       " '   Computer skills: Advanced in Microsoft Word, Outlook, PowerPoint, intermediate in Excel',\n",
       " ' Comfortable with learning new applications and POS systems',\n",
       " '   Highly responsible and able to work with minimal supervision',\n",
       " '   Proven ability to work under pressure with a great degree of focus and attention to details',\n",
       " '   Natural ability to negotiate and build relationships with new people',\n",
       " '   Friendly and enthusiastic in a team',\n",
       " '']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the text for \\n and ● and split into sentences\n",
    "raw_text = raw_text.replace('\\n', ' ') \n",
    "raw_text = raw_text.replace('●', ' ')\n",
    "\n",
    "raw_text = raw_text.split('.')\n",
    "\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks cleaner and more distinguishible for the embedding model. Next we will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Embeddings for the document and storing vectors in Pinecone "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to initialize our connection to Pinecone though a free API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "\n",
    "# add Pinecone API key from app.pinecone.io\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\") or \"your_api_key\"\n",
    "# set Pinecone environment - find next to API key in console\n",
    "env = os.environ.get(\"PINECONE_ENVIRONMENT\") or \"gcp-starter\"\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['retrieval-augmentation-aws']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'retrieval-augmentation-aws' # name of the index\n",
    "\n",
    "if index_name in pinecone.list_indexes(): # delete index if it already exists\n",
    "    pinecone.delete_index(index_name)\n",
    "    \n",
    "pinecone.create_index( # create index\n",
    "    name=index_name,\n",
    "    dimension=embeddings.shape[1],\n",
    "    metric='cosine' # cosine similarity\n",
    ")\n",
    "# wait for index to finish initialization\n",
    "while not pinecone.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1) # wait 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['retrieval-augmentation-aws']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 2 # batch size for upsert\n",
    "vector_limit = 100 # limit the number of vectors to upload\n",
    "\n",
    "texts = raw_text[:vector_limit] # limit the number of vectors to upload\n",
    "index = pinecone.Index(index_name) \n",
    "\n",
    "for i in tqdm(range(0, len(raw_text), batch_size)): # iterate over batches\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(raw_text)) \n",
    "    # create IDs batch\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # create metadata batch\n",
    "    metadatas = [{'text': text} for text in raw_text[i:i_end]]\n",
    "    # create embeddings\n",
    "    embeddings = embed_docs(raw_text[i:i_end]) # embed_docs is a function that embeds a list of documents\n",
    "    # create records list for upsert\n",
    "    records = zip(ids, embeddings, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records) # upsert vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.00025,\n",
       " 'namespaces': {'': {'vector_count': 25}},\n",
       " 'total_vector_count': 25}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of records in the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the retrieved pdf, prompt, and question to query the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will finally be able to ask LLM a question based on the document we uploaded. The first step is to embed the question. As you might remember from an earlier section, we had a question about my education.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What is Diana's education?\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '0',\n",
       "              'metadata': {'text': 'Diana Rogachova (2019 resume) OBJECTIVE I '\n",
       "                                   'am a highly dependable and well-or ganized '\n",
       "                                   'individual seeking part-time employment in '\n",
       "                                   'the customer service industry '},\n",
       "              'score': 0.336022854,\n",
       "              'values': []},\n",
       "             {'id': '20',\n",
       "              'metadata': {'text': '   Highly responsible and able to work '\n",
       "                                   'with minimal supervision'},\n",
       "              'score': 0.294900119,\n",
       "              'values': []},\n",
       "             {'id': '21',\n",
       "              'metadata': {'text': '   Proven ability to work under pressure '\n",
       "                                   'with a great degree of focus and attention '\n",
       "                                   'to details'},\n",
       "              'score': 0.249704123,\n",
       "              'values': []},\n",
       "             {'id': '16',\n",
       "              'metadata': {'text': '   Clear and strong communication skills'},\n",
       "              'score': 0.249647334,\n",
       "              'values': []},\n",
       "             {'id': '13',\n",
       "              'metadata': {'text': ' EDUCA TION Bachelor of Arts Honours in '\n",
       "                                   'Criminology and Criminal Justice System: '\n",
       "                                   '2017-2021 Psychology Concentration '\n",
       "                                   'Carleton University , Ottawa, ON   Current '\n",
       "                                   'CGPA: 11'},\n",
       "              'score': 0.244830221,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embeddings for the questions\n",
    "query_vec = embed_docs(question)[0] # embedding a single question\n",
    "\n",
    "# query pinecone\n",
    "res = index.query(query_vec, top_k=5, include_metadata=True)\n",
    "\n",
    "# show the results\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did above is we retrieved the contents relevant to the question. As seen above, these are several different contexts. We can use them to create a single context and feed them to our LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contexts = [match.metadata['text'] for match in res.matches] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_section_len = 10000 # maximum length of the concatenated document\n",
    "separator = \"\\n\" \n",
    "\n",
    "def construct_context(contexts: List[str]) -> str: \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "\n",
    "    for text in contexts:\n",
    "        text = text.strip() # remove leading and trailing whitespace\n",
    "        # Add contexts until we run out of space.\n",
    "        chosen_sections_len += len(text) + 2 \n",
    "        if chosen_sections_len > max_section_len:\n",
    "            break\n",
    "        chosen_sections.append(text)\n",
    "    concatenated_doc = separator.join(chosen_sections)\n",
    "    print(\n",
    "        f\"With maximum sequence length {max_section_len}, selected top {len(chosen_sections)} document sections: \\n{concatenated_doc}\"\n",
    "    )\n",
    "    return concatenated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry\n",
      "Highly responsible and able to work with minimal supervision\n",
      "Proven ability to work under pressure with a great degree of focus and attention to details\n",
      "Clear and strong communication skills\n",
      "EDUCA TION Bachelor of Arts Honours in Criminology and Criminal Justice System: 2017-2021 Psychology Concentration Carleton University , Ottawa, ON   Current CGPA: 11\n"
     ]
    }
   ],
   "source": [
    "context_str = construct_context(contexts=contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed this concatenated context into an LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input]: What is Diana's education?\n",
      "[Output]: Bachelor of Arts Honours in Criminology and Criminal Justice System: 2017-2021 Psychology Concentr\n"
     ]
    }
   ],
   "source": [
    "text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
    "\n",
    "out = llm.predict({\"inputs\": text_input})\n",
    "generated_text = out[0][\"generated_text\"]\n",
    "print(f\"[Input]: {question}\\n[Output]: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_query(question: str) -> str: # function to query the index and return the generated answer\n",
    "    # create query vec\n",
    "    query_vec = embed_docs(question)[0]\n",
    "    # query pinecone\n",
    "    res = index.query(query_vec, top_k=5, include_metadata=True)\n",
    "    # get contexts\n",
    "    contexts = [match.metadata['text'] for match in res.matches]\n",
    "    # build the multiple contexts string\n",
    "    context_str = construct_context(contexts=contexts)\n",
    "    # create our retrieval augmented prompt\n",
    "    text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
    "    # make prediction\n",
    "    out = llm.predict({\"inputs\": text_input})\n",
    "    return out[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry\n",
      "Highly responsible and able to work with minimal supervision\n",
      "Proven ability to work under pressure with a great degree of focus and attention to details\n",
      "Clear and strong communication skills\n",
      "EDUCA TION Bachelor of Arts Honours in Criminology and Criminal Justice System: 2017-2021 Psychology Concentration Carleton University , Ottawa, ON   Current CGPA: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bachelor of Arts Honours in Criminology and Criminal Justice System: 2017-2021 Psychology Concentr'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"What is Diana's Education?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry\n",
      "Cashier and Food Server Kettleman’ s Bagel Co, Bank St, Ottawa, ON April 2017 – August 2018   Demonstrated an excellent ability to multitask and strengthened priority management skills while working in a high volume, fast paced café\n",
      "WORK EXPERIENCE Cashier The Riv’s Snack Bar, Sparks St, Ottawa, ON June 2019 – Curr ent   Demonstrated ability to provide outstanding customer service by accurately taking orders and addressing customer inquiries with a friendly and professional demeanor\n",
      "Sales Associate (Sunday only position) The Unrefined Olive, Bank St, Ottawa, ON September 2018 – Curr ent   Strengthened interpersonal and presentation skills by providing an informative service to each individual customer\n",
      "Highly responsible and able to work with minimal supervision\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kettleman’ s Bagel Co'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"Where did she work in 2017-2018?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Fluent in English, Russian and Ukrainian\n",
      "Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry\n",
      "Highly responsible and able to work with minimal supervision\n",
      "EDUCA TION Bachelor of Arts Honours in Criminology and Criminal Justice System: 2017-2021 Psychology Concentration Carleton University , Ottawa, ON   Current CGPA: 11\n",
      "Cashier and Food Server Kettleman’ s Bagel Co, Bank St, Ottawa, ON April 2017 – August 2018   Demonstrated an excellent ability to multitask and strengthened priority management skills while working in a high volume, fast paced café\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ottawa'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"Which city does she live in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Often supervised 4-6 employees during busy overnight shifts with the goal of completion of main tasks (wholesale orders, baking for morning shifts, cleaning up, etc)\n",
      "Highly responsible and able to work with minimal supervision\n",
      "Proven track record of collaborating effectively with bartenders, cooks, management and other staff streamlining the operations\n",
      "Further developed organizational and time-management skills by performing most of the store’ s operations without supervision, such as opening/closing, operating a cash register , answering phone calls, etc\n",
      "Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4-6'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"How many employees did she supervise?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Diana Rogachova (2019 resume) OBJECTIVE I am a highly dependable and well-or ganized individual seeking part-time employment in the customer service industry\n",
      "Highly responsible and able to work with minimal supervision\n",
      "WORK EXPERIENCE Cashier The Riv’s Snack Bar, Sparks St, Ottawa, ON June 2019 – Curr ent   Demonstrated ability to provide outstanding customer service by accurately taking orders and addressing customer inquiries with a friendly and professional demeanor\n",
      "Proven track record of collaborating effectively with bartenders, cooks, management and other staff streamlining the operations\n",
      "Further developed organizational and time-management skills by performing most of the store’ s operations without supervision, such as opening/closing, operating a cash register , answering phone calls, etc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'customer service'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"Which industry she wants to find work in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With maximum sequence length 10000, selected top 5 document sections: \n",
      "Computer skills: Advanced in Microsoft Word, Outlook, PowerPoint, intermediate in Excel\n",
      "Clear and strong communication skills\n",
      "Highly responsible and able to work with minimal supervision\n",
      "Coached new employees in the computer system and improved their performance which increased the efficiency of their training\n",
      "Proven ability to work under pressure with a great degree of focus and attention to details\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Advanced in Microsoft Word, Outlook, PowerPoint, intermediate in Excel'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query(\"What are her computer skills?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
